{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "best_value = 0\n",
    "depth = 8\n",
    "random_state = 114\n",
    "n_estimators = 100\n",
    "data_table = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "X = data_table.drop('Outcome', axis=1).values\n",
    "y = data_table['Outcome'].values\n",
    "features = data_table.drop('Outcome', axis=1).columns.to_list()\n",
    "#X = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=random_state)\n",
    "\n",
    "sm = SMOTE(random_state=random_state)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "clf = LGBMClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    num_leaves=50,\n",
    "    reg_alpha=3,\n",
    "    max_depth=8,\n",
    "    random_state=random_state,\n",
    ")\n",
    "'''\n",
    "random_state = 114\n",
    "criterion = \"entropy\"\n",
    "max_depth = 8\n",
    "max_features = \"sqrt\"\n",
    "n_estimators = 150\n",
    "max_leaf_nodes = 90\n",
    "bootstrap = True\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    max_leaf_nodes=max_leaf_nodes,\n",
    "    max_features=max_features,\n",
    "    bootstrap=bootstrap,\n",
    "    criterion=criterion, \n",
    "    max_depth=max_depth,\n",
    "    random_state=random_state,\n",
    "    n_estimators=n_estimators,\n",
    ")\n",
    "'''\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Test')\n",
    "print('Accuracy Score is', accuracy_score(y_test, y_pred))\n",
    "#rint('Precision is', precision_score(y_test, y_pred))\n",
    "#print('Recall is', recall_score(y_test, y_pred))\n",
    "#print('F1-Score is', f1_score(y_test, y_pred))\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "print('Train')\n",
    "print('Accuracy Score is', accuracy_score(y_train, y_pred))\n",
    "#print('Precision is', precision_score(y_train, y_pred))\n",
    "#print('Recall is', recall_score(y_train, y_pred))\n",
    "#print('F1-Score is', f1_score(y_train, y_pred))\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joblib'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c0/_jqltvjd66x2xvy00lkf85wr0000gn/T/ipykernel_30733/1251192259.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m from .utils._tags import (\n\u001b[1;32m     19\u001b[0m     \u001b[0m_DEFAULT_TAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# mypy error: Module 'numpy.core.numeric' has no attribute 'ComplexWarning'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumeric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComplexWarning\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcontextlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'joblib'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "from tree_extractor import path_extractor\n",
    "paths = path_extractor(clf, 'random forest', (X_train, y_train))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "def path_predict(paths, X, y):\n",
    "    Y = np.zeros(X.shape[0])\n",
    "    for p in paths:\n",
    "        ans = np.ones(X.shape[0])\n",
    "        m = p.get('range')\n",
    "        for key in m:\n",
    "            ans = ans * (X[:,int(key)] >= m[key][0]) * (X[:,int(key)] < m[key][1])\n",
    "        Y += ans * (p.get('weight') * p.get('value'))\n",
    "    Y = np.where(Y > 0, 1, 0)\n",
    "    return (Y == y).sum() / len(y)\n",
    "\n",
    "print('train', path_predict(paths, X_train, y_train))\n",
    "print('test', path_predict(paths, X_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train 1.0\n",
      "test 0.9532163742690059\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import pulp\n",
    "from copy import deepcopy\n",
    "\n",
    "class Extractor:\n",
    "    # 可以调用的接口：compute_accuracy和extract\n",
    "    def __init__(self, paths, X_train, y_train, X_test, y_test):\n",
    "        # X_raw、y_raw：训练数据集\n",
    "        self.X_raw = X_train\n",
    "        self.y_raw = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.paths = paths\n",
    "        print('paths', len(paths))\n",
    "\n",
    "    def compute_accuracy_on_train(self, paths):\n",
    "        # 计算训练集在给定规则集下的accuracy\n",
    "        # paths：规则集\n",
    "        y_pred = self.predict(self.X_raw, paths)\n",
    "        y_pred = np.where(y_pred == 1, 1, 0)\n",
    "        return np.sum(np.where(y_pred == self.y_raw, 1, 0)) / len(self.X_raw)\n",
    "\n",
    "    def compute_accuracy_on_test(self, paths):\n",
    "        # 计算测试集在给定规则集下的accuracy\n",
    "        # paths：规则集\n",
    "        y_pred = self.predict(self.X_test, paths)\n",
    "        y_pred = np.where(y_pred == 1, 1, 0)\n",
    "        return np.sum(np.where(y_pred == self.y_test, 1, 0)) / len(self.X_test)\n",
    "\n",
    "    def extract(self, max_num, tau):\n",
    "        # 根据给定的max_num和tau，使用rf的全部规则和数据集抽取出相应的规则\n",
    "        # max_num：抽取出规则的最大数量\n",
    "        # tau：每个样本允许的最大惩罚\n",
    "        # 返回抽取出规则的列表、数据集使用全部规则的accuracy、数据集使用抽取规则的accuracy\n",
    "        Mat = self.getMat(self.X_raw, self.y_raw, self.paths)\n",
    "        print('getWeight')\n",
    "        w = self.getWeight(self.getMat(self.X_raw, self.y_raw, self.paths))\n",
    "        print('LP_extraction')\n",
    "        paths_weight = self.LP_extraction(w, Mat, max_num, tau)\n",
    "        print('compute_accuracy_on_test')\n",
    "        accuracy_origin = self.compute_accuracy_on_test(self.paths)\n",
    "        accuracy_origin1 = self.compute_accuracy_on_train(self.paths)\n",
    "        path_copy = deepcopy(self.paths)\n",
    "        for i in range(len(path_copy)):\n",
    "            path_copy[i]['weight'] *= paths_weight[i]\n",
    "        accuracy_new = self.compute_accuracy_on_test(path_copy)\n",
    "        accuracy_new1 = self.compute_accuracy_on_train(path_copy)\n",
    "        return paths_weight, accuracy_origin1, accuracy_new1, accuracy_origin, accuracy_new\n",
    "\n",
    "    def predict(self, X, paths):\n",
    "        # 根据给定规则集对数据进行预测\n",
    "        Y = np.zeros(X.shape[0])\n",
    "        for p in paths:\n",
    "            ans = np.ones(X.shape[0])\n",
    "            m = p.get('range')\n",
    "            for key in m:\n",
    "                ans = ans * (X[:,int(key)] >= m[key][0]) * (X[:,int(key)] < m[key][1])\n",
    "            Y += ans * (p.get('weight') * p.get('value'))\n",
    "        Y = np.where(Y > 0, 1, 0)\n",
    "        return Y\n",
    "\n",
    "    def getMat(self, X_raw, y_raw, paths):\n",
    "        Mat = np.array([self.path_score(p, X_raw, y_raw) for p in paths]).astype('float')\n",
    "        return Mat\n",
    "\n",
    "    def path_score(self, path, X, y):\n",
    "        value = float(path.get('value'))\n",
    "        ans = 2 * (value * y > 0) - 1\n",
    "        m = path.get('range')\n",
    "        for key in m:\n",
    "            ans = ans * (X[:, int(key)] >= m[key][0]) * (X[:, int(key)] < m[key][1])\n",
    "        return ans\n",
    "\n",
    "    def getWeight(self, Mat):\n",
    "        # 权重向量w\n",
    "        RXMat = np.abs(Mat)\n",
    "        XRMat = RXMat.transpose()\n",
    "        XXAnd = np.dot(XRMat, RXMat)\n",
    "        XROne = np.ones(XRMat.shape)\n",
    "        XXOr = 2 * np.dot(XROne, RXMat) - XXAnd\n",
    "        XXOr = (XXOr + XXOr.transpose()) / 2\n",
    "        XXDis = 1 - XXAnd / XXOr\n",
    "        K = int(np.ceil(np.sqrt(len(self.X_raw))))\n",
    "        clf = LocalOutlierFactor(n_neighbors=K, metric=\"precomputed\")\n",
    "        clf.fit(XXDis)\n",
    "        XW = -clf.negative_outlier_factor_\n",
    "        MXW, mXW = np.max(XW), np.min(XW)\n",
    "        XW = 1 + (1 - 1) * (XW - mXW) / (MXW - mXW)\n",
    "        return XW / np.sum(XW)\n",
    "\n",
    "    def LP_extraction(self, w, Mat, max_num, tau):\n",
    "        m = pulp.LpProblem(sense=pulp.LpMinimize)\n",
    "        # 创建最小化问题\n",
    "        var = []\n",
    "        for i in range(len(self.paths)):\n",
    "            var.append(pulp.LpVariable(f'x{i}', cat=pulp.LpContinuous, lowBound=0, upBound=1))\n",
    "        for i in range(len(w)):\n",
    "            var.append(pulp.LpVariable(f'k{i}', cat=pulp.LpContinuous, lowBound=0))\n",
    "        # 添加变量x_0至x_{M-1}, k_0至k_{N-1}\n",
    "\n",
    "        m += pulp.lpSum([w[j] * (var[j + len(self.paths)])\n",
    "                         for j in range(len(w))])\n",
    "        # 添加目标函数\n",
    "\n",
    "        m += (pulp.lpSum([var[j] for j in range(len(self.paths))]) <= max_num)\n",
    "        # 筛选出不超过max_num条规则\n",
    "\n",
    "        for j in range(len(w)):\n",
    "            m += (var[j + len(self.paths)] >= 1000 + tau - pulp.lpSum(\n",
    "                [var[k] * Mat[k][j] for k in range(len(self.paths))]))\n",
    "            m += (var[j + len(self.paths)] >= 1000)\n",
    "            # max约束\n",
    "\n",
    "        m.solve(pulp.PULP_CBC_CMD())  # solver = pulp.solver.CPLEX())#\n",
    "        paths_weight = [var[i].value() for i in range(len(self.paths))]\n",
    "        paths_weight = np.array(paths_weight)\n",
    "        paths_weight = paths_weight / np.sum(paths_weight)\n",
    "        return paths_weight\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "ex = Extractor(paths, X_train, y_train, X_test, y_test)\n",
    "ret = ex.extract(100, 2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "paths 2407\n",
      "getWeight\n",
      "LP_extraction\n",
      "compute_accuracy_on_test\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "print(ret[1:])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1.0, 1.0, 0.9532163742690059, 0.9239766081871345)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "print(ret[1:])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0.9861660079051383, 0.9920948616600791, 0.9415204678362573, 0.9590643274853801)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "ex = Extractor(rf, X_train, y_train, X_test, y_test)\n",
    "ret = ex.extract(50, 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "print(ret[2:])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0.8, 0.8133333333333334)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "paths = rf.get_paths()\n",
    "\n",
    "all_paths = []\n",
    "for t in paths:\n",
    "    all_paths = all_paths + t"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1337d84936ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_paths\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-538815d23862>\u001b[0m in \u001b[0;36mget_paths\u001b[0;34m(self, min_impurity_decrease)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_impurity_decrease\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             self.dfs(i, 0, {}, np.ones(self.n_examples),\n\u001b[0m\u001b[1;32m     62\u001b[0m                      np.ones(self.n_examples2))\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-538815d23862>\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(self, i, u, feature_range, vec_examples, vec_examples2)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             self.dfs(\n\u001b[0m\u001b[1;32m    118\u001b[0m                 i, tr.children_left[u], _feature_range, _vec_examples, _vec_examples2)\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-538815d23862>\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(self, i, u, feature_range, vec_examples, vec_examples2)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             self.dfs(\n\u001b[0m\u001b[1;32m    118\u001b[0m                 i, tr.children_left[u], _feature_range, _vec_examples, _vec_examples2)\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-538815d23862>\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(self, i, u, feature_range, vec_examples, vec_examples2)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             self.dfs(\n\u001b[0m\u001b[1;32m    118\u001b[0m                 i, tr.children_left[u], _feature_range, _vec_examples, _vec_examples2)\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-538815d23862>\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(self, i, u, feature_range, vec_examples, vec_examples2)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             self.dfs(\n\u001b[0m\u001b[1;32m    118\u001b[0m                 i, tr.children_left[u], _feature_range, _vec_examples, _vec_examples2)\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-538815d23862>\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(self, i, u, feature_range, vec_examples, vec_examples2)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0m_vec_examples2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec_examples2\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             self.dfs(\n\u001b[0m\u001b[1;32m    130\u001b[0m                 i, tr.children_right[u], _feature_range, _vec_examples, _vec_examples2)\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-538815d23862>\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(self, i, u, feature_range, vec_examples, vec_examples2)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren_left\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren_right\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mimpurity_decrease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             distribution = [np.dot(vec_examples, self.y == cid)\n\u001b[1;32m     85\u001b[0m                             for cid in range(self.n_categories)]\n",
      "\u001b[0;32m<ipython-input-4-538815d23862>\u001b[0m in \u001b[0;36mimpurity_decrease\u001b[0;34m(tr, u)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mN_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_node_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mI_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpurity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mN_t\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_t\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mN_r\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN_t\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mI_r\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mN_l\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN_t\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mI_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(r_clf)\n",
    "shap_values = explainer(X)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "\n",
    "features=[\n",
    "    {\n",
    "        \"name\": rf.features[i],\n",
    "        \"lbound\":rf.feature_range[0][i],\n",
    "        \"rbound\":rf.feature_range[1][i],\n",
    "        \"importance\":r_clf.feature_importances_[i],\n",
    "        \"options\":\"+\",\n",
    "    } for i in range(rf.n_features)\n",
    "]\n",
    "\n",
    "data = {\n",
    "    'paths': all_paths,\n",
    "    'features': features,\n",
    "    'selected': ret[0],\n",
    "    'shap_values': shap_values,\n",
    "}\n",
    "\n",
    "import pickle\n",
    "pickle.dump(data, open('output/german.pkl', 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "print(shap_values[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".values =\n",
      "array([[ 1.09110125e-01, -1.09110125e-01],\n",
      "       [ 3.01264698e-03, -3.01264698e-03],\n",
      "       [-1.24874332e-01,  1.24874332e-01],\n",
      "       [ 2.10891519e-03, -2.10891519e-03],\n",
      "       [-1.99799022e-02,  1.99799022e-02],\n",
      "       [ 3.40283799e-02, -3.40283799e-02],\n",
      "       [ 3.85628726e-02, -3.85628726e-02],\n",
      "       [ 5.60976830e-03, -5.60976830e-03],\n",
      "       [ 3.36153339e-02, -3.36153339e-02],\n",
      "       [ 3.85308858e-03, -3.85308858e-03],\n",
      "       [-2.39386825e-02,  2.39386825e-02],\n",
      "       [ 7.02421386e-03, -7.02421386e-03],\n",
      "       [ 1.96232689e-02, -1.96232689e-02],\n",
      "       [-1.74483971e-02,  1.74483971e-02],\n",
      "       [ 6.65478065e-02, -6.65478065e-02],\n",
      "       [ 6.73321595e-03, -6.73321595e-03],\n",
      "       [ 1.58162875e-03, -1.58162875e-03],\n",
      "       [-6.93273863e-05,  6.93273863e-05],\n",
      "       [ 5.12965848e-03, -5.12965848e-03],\n",
      "       [ 2.51444887e-03, -2.51444887e-03]])\n",
      "\n",
      ".base_values =\n",
      "array([0.50028956, 0.49971044])\n",
      "\n",
      ".data =\n",
      "array([   1,   18,    4,    2, 1049,    1,    2,    4,    2,    1,    4,\n",
      "          2,   21,    3,    1,    1,    3,    1,    1,    1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "ret[0][3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'r99-69'"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "data = pd.read_csv('data/german.data', sep=',')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "data[data.columns[3]].dtype == 'O'"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ea3477afad61d1acfc7a79462b4a6ce79d4aef9f14d4a4945c1028f752d51099"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}